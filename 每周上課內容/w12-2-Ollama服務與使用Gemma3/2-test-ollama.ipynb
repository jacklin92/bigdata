{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "471af8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在檢查 Ollama 服務器連接 (http://163.18.22.32:11435)...\n",
      "連接成功！可用模型: gemma3:4b\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import sys\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# 設置 Ollama 服務器地址\n",
    "OLLAMA_HOST = \"http://163.18.22.32:11435\"\n",
    "ollama.host = OLLAMA_HOST\n",
    "\n",
    "# 在程式開始時檢查連接\n",
    "print(f\"正在檢查 Ollama 服務器連接 ({OLLAMA_HOST})...\")\n",
    "try:\n",
    "    # 嘗試獲取可用模型列表以測試連接\n",
    "    response = requests.get(f\"{OLLAMA_HOST}/api/tags\")\n",
    "    if response.status_code == 200:\n",
    "        models = response.json()\n",
    "        available_models = [model['name'] for model in models['models']]\n",
    "        print(f\"連接成功！可用模型: {', '.join(available_models)}\")\n",
    "    else:\n",
    "        print(f\"連接失敗，服務器返回狀態碼: {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"無法連接到 Ollama 服務器: {e}\")\n",
    "    print(\"請檢查:\")\n",
    "    print(\"1. Ollama 服務器是否正在運行\")\n",
    "    print(\"2. 網絡連接是否正常\")\n",
    "    print(\"3. 防火牆設置是否允許連接\")\n",
    "    print(\"4. IP 地址和端口是否正確\")\n",
    "    sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce6946ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "使用 gemma3:4b 生成內容...\n",
      "\n",
      "回應:\n",
      "好的，我們來用簡單的方式解釋大數據分析：\n",
      "\n",
      "**想像一下，你有一堆超級多的東西，比你平常處理的資料還要多好幾百倍甚至上千倍。**\n",
      "\n",
      "*   這些東西可以是：網路上每個人的瀏覽記錄、購物紀錄、社群媒體上的發文、感測器收集到的環境數據、股票交易紀錄等等。\n",
      "*   這些資料量非常龐大，傳統的電腦軟體和方法處理起來，就像在沙灘上用勺子舀水，非常慢而且效率很低。\n",
      "\n",
      "**大數據分析就是用特別的工具和方法，去從這些超級多的資料裡，挖掘出有用的資訊和規律。**\n",
      "\n",
      "**更詳細的解釋：**\n",
      "\n",
      "1.  **「大數據」 (Big Data):** 指的是超出傳統數據處理工具和方法所能處理的資料量，通常包含以下四個特徵：\n",
      "    *   **Volume (數量):** 資料量非常大。\n",
      "    *   **Velocity (速度):** 資料產生和更新的速度非常快。\n",
      "    *   **Variety (多樣性):** 資料的類型非常多，例如文字、圖片、影片、數字等等。\n",
      "    *   **Veracity (真實性):** 資料的品質和準確性可能不一致。\n",
      "\n",
      "2.  **分析的目的：** 透過大數據分析，我們可以：\n",
      "    *   **預測未來:**  例如，根據過去的銷售紀錄，預測未來哪些商品會賣得好。\n",
      "    *   **改善決策:**  例如，根據顧客的瀏覽行為，調整產品推薦策略。\n",
      "    *   **發現隱藏的關係:** 例如，找出哪些因素會導致某些疾病的發生。\n",
      "    *   **優化業務流程:**  例如，根據交通流量數據，優化交通路線。\n",
      "\n",
      "3.  **使用的工具和方法：** 大數據分析需要用到一些特殊的工具和方法，例如：\n",
      "    *   **機器學習:**  讓電腦自己學習資料中的規律，並根據這些規律進行預測或分類。\n",
      "    *   **數據挖掘:**  從資料中發現有價值的模式和關係。\n",
      "    *   **雲計算:**  提供大數據分析所需的計算能力和儲存空間。\n",
      "\n",
      "**簡單來說，大數據分析就是把大量、多樣的數據變成有用的信息，幫助我們做出更好的決策！**\n",
      "\n",
      "希望這個解釋對你有幫助！\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用 requests 直接調用 Ollama API 生成文本\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# 設置 Ollama 服務器地址\n",
    "OLLAMA_HOST = \"http://163.18.22.32:11435\"\n",
    "\n",
    "# 簡單的文本生成示例\n",
    "model_name = \"gemma3:4b\"  # 使用您有的模型名稱\n",
    "prompt = \"解釋什麼是大數據分析？請用簡單的語言說明。\"\n",
    "\n",
    "print(f\"\\n使用 {model_name} 生成內容...\")\n",
    "try:\n",
    "    # 構建 API 請求\n",
    "    url = f\"{OLLAMA_HOST}/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    # 發送請求\n",
    "    response = requests.post(url, json=payload)\n",
    "    \n",
    "    # 檢查響應\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        print(\"\\n回應:\")\n",
    "        print(result['response'])\n",
    "    else:\n",
    "        print(f\"API 返回錯誤: {response.status_code}\")\n",
    "        print(response.text)\n",
    "except Exception as e:\n",
    "    print(f\"生成時發生錯誤: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9316914a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "與 gemma3:4b 進行對話...\n",
      "\n",
      "助理回應:\n",
      "我是Google DeepMind訓練的大型語言模型，叫做Gemma。 \n",
      "\n",
      "我是一個開放權重的模型，可以與你進行對話，並根據你的指示生成文本。 \n",
      "\n",
      "簡而言之，我是一個人工智能助手！ 😊\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用 requests 直接調用 Ollama API 進行聊天\n",
    "import requests\n",
    "\n",
    "# 設置 Ollama 服務器地址\n",
    "OLLAMA_HOST = \"http://163.18.22.32:11435\"\n",
    "\n",
    "# 聊天示例\n",
    "model_name = \"gemma3:4b\"  # 使用您有的模型名稱\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"你好，你能告訴我你是誰嗎？\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"\\n與 {model_name} 進行對話...\")\n",
    "try:\n",
    "    # 構建 API 請求\n",
    "    url = f\"{OLLAMA_HOST}/api/chat\"\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    # 發送請求\n",
    "    response = requests.post(url, json=payload)\n",
    "    \n",
    "    # 檢查響應\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        assistant_message = result['message']['content']\n",
    "        print(\"\\n助理回應:\")\n",
    "        print(assistant_message)\n",
    "    else:\n",
    "        print(f\"API 返回錯誤: {response.status_code}\")\n",
    "        print(response.text)\n",
    "except Exception as e:\n",
    "    print(f\"聊天時發生錯誤: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69c01caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "使用 gemma3:4b 串流生成內容...\n",
      "\n",
      "回應: 好的，以下是一篇關於資料科學重要性的短文：\n",
      "\n",
      "**資料科學：數據驅動的未來**\n",
      "\n",
      "在當今時代，我們被無數數據所淹沒。從消費者的購買記錄到網路用戶的瀏覽行為，從天氣模式到生物數據，數據無所不在。然而，這些數據本身並沒有價值，它們只有在經過分析和理解後，才能轉化為有用的洞見，並推動各種行業的創新和發展。這就是資料科學的重要性所在。\n",
      "\n",
      "資料科學是一個跨領域的學科，它結合了統計學、機器學習、數據挖掘、資訊工程和商業知識，旨在從大量數據中提取知識和趨勢。資料科學家使用各種工具和技術，例如機器學習算法、數據庫和大數據平台，來分析數據，建立模型，並預測未來趨勢。\n",
      "\n",
      "資料科學的重要性體現在以下幾個方面：\n",
      "\n",
      "* **改善決策：** 透過數據分析，企業和組織可以做出更明智的決策，優化營運效率，降低風險。\n",
      "* **創新產品與服務：**  資料科學可以幫助企業了解消費者的需求和偏好，從而開發出更符合市場需求的新產品和服務。\n",
      "* **優化流程：**  透過數據分析，企業可以識別流程中的瓶頸，並加以改進，提高效率和降低成本。\n",
      "* **預測趨勢：**  資料科學可以幫助我們預測市場趨勢、消費者行為和潛在的風險，從而做出更有效的應對措施。\n",
      "\n",
      "隨著大數據時代的來臨，資料科學將在各行各業扮演越來越重要的角色。它不僅僅是一種技術，更是一種思維方式，一種以數據為基礎的解決問題的全新方法。那些能夠善用資料科學的人，將在未來擁有更大的競爭優勢。\n",
      "\n",
      "---\n",
      "\n",
      "希望這篇短文對您有所幫助！您想讓我修改或調整哪些方面呢？例如，我可以調整長度，或著增加一些特定的應用場景。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用 requests 直接調用 Ollama API 進行串流生成\n",
    "import requests\n",
    "\n",
    "# 設置 Ollama 服務器地址\n",
    "OLLAMA_HOST = \"http://163.18.22.32:11435\"\n",
    "\n",
    "# 串流生成示例\n",
    "model_name = \"gemma3:4b\"  # 使用您有的模型名稱\n",
    "prompt = \"撰寫一個關於資料科學重要性的短文。\"\n",
    "\n",
    "print(f\"\\n使用 {model_name} 串流生成內容...\")\n",
    "print(\"\\n回應: \", end=\"\", flush=True)\n",
    "try:\n",
    "    # 構建 API 請求\n",
    "    url = f\"{OLLAMA_HOST}/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": True\n",
    "    }\n",
    "    \n",
    "    # 發送串流請求\n",
    "    with requests.post(url, json=payload, stream=True) as response:\n",
    "        if response.status_code == 200:\n",
    "            for line in response.iter_lines():\n",
    "                if line:\n",
    "                    # 解析 JSON 數據\n",
    "                    data = json.loads(line.decode('utf-8'))\n",
    "                    if 'response' in data:\n",
    "                        print(data['response'], end=\"\", flush=True)\n",
    "            print(\"\\n\")\n",
    "        else:\n",
    "            print(f\"\\nAPI 返回錯誤: {response.status_code}\")\n",
    "            print(response.text)\n",
    "except Exception as e:\n",
    "    print(f\"\\n生成時發生錯誤: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625cac2d",
   "metadata": {},
   "source": [
    "# 另一方式使用chat() generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd9d3279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "# 設置遠程 Ollama 模型的基礎 URL\n",
    "REMOTE_OLLAMA_URL = \"http://163.18.22.32:11435\"\n",
    "# 創建客戶端實例\n",
    "client = ollama.Client(host=REMOTE_OLLAMA_URL)\n",
    "\n",
    "# 設置要使用的模型名稱\n",
    "model_name = \"gemma3:4b\" # 默認模型名稱\n",
    "#model_name = \"llama3:latest\"\n",
    "#model_name = \"deepseek-r1:7b\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f7cb15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# This is a markdown heading\n",
       "\n",
       "- This is a bullet point\n",
       "- Another bullet point\n",
       "\n",
       "**Bold text** and *italic text*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def display_markdown(text):\n",
    "    \"\"\"\n",
    "    Display text as rendered markdown in the notebook\n",
    "    \n",
    "    Args:\n",
    "        text (str): The markdown text to render\n",
    "    \"\"\"\n",
    "    display(Markdown(text))\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Example usage\n",
    "example_text = \"\"\"\n",
    "# This is a markdown heading\n",
    "\n",
    "- This is a bullet point\n",
    "- Another bullet point\n",
    "\n",
    "**Bold text** and *italic text*\n",
    "\"\"\"\n",
    "display_markdown(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89c9e996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# This is a markdown heading\n",
       "\n",
       "- This is a bullet point\n",
       "- Another bullet point\n",
       "\n",
       "**Bold text** and *italic text*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(example_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "650a2be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# This is a markdown heading\n",
       "\n",
       "- This is a bullet point\n",
       "- Another bullet point\n",
       "\n",
       "**Bold text** and *italic text*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e6c14d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "使用 gemma3:4b 生成內容...\n",
      "\n",
      "回應:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "好的，讓我用簡單的語言解釋大數據分析：\n",
       "\n",
       "**想像一下，你有一個超級大的儲藏室，裡面塞滿了各種各樣的資訊。** 這些資訊可能來自：\n",
       "\n",
       "*   網站上的瀏覽紀錄\n",
       "*   手機App的使用情況\n",
       "*   社交媒體上的討論\n",
       "*   銷售記錄\n",
       "*   天氣數據\n",
       "*   甚至是感測器從各種設備發送的訊息\n",
       "\n",
       "**這種情況下，我們就進入了“大數據”的範圍。** 因為資訊量實在太大了，傳統的電腦或分析方法根本無法處理。\n",
       "\n",
       "**大數據分析就是指利用特殊的技術和方法，從這些海量、多樣、快速變動的數據中，挖掘出有用的資訊和趨勢。**\n",
       "\n",
       "**簡單來說，就是：**\n",
       "\n",
       "1.  **收集：** 收集大量的數據。\n",
       "2.  **處理：** 清理和整理這些數據，讓它變得有意義。\n",
       "3.  **分析：**  運用技術（像是機器學習）來找出數據中的模式、關係和趨勢。\n",
       "4.  **應用：**  利用分析結果，幫助企業或組織做出更好的決策，例如：\n",
       "    *   **零售：**  了解顧客喜歡什麼、在哪裡購買、以及如何提供更個人化的購物體驗。\n",
       "    *   **醫療：**  找出疾病的早期徵兆、改善治療方案。\n",
       "    *   **交通：**  優化交通流量、減少擁堵。\n",
       "\n",
       "**關鍵的技術：**\n",
       "\n",
       "*   **機器學習：**  讓電腦可以自己從數據中學習，並預測未來趨勢。\n",
       "*   **數據挖掘：**  從數據中發現隱藏的模式。\n",
       "*   **雲計算：**  提供儲存和處理大數據的平台。\n",
       "\n",
       "**總之，大數據分析不是簡單的統計，而是利用科技，從海量數據中尋找真正有價值的資訊。**\n",
       "\n",
       "希望這個解釋對您有幫助！"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 簡單的文本生成示例\n",
    "model_name = \"gemma3:4b\"  # 使用您有的模型名稱\n",
    "prompt = \"解釋什麼是大數據分析？請用簡單的語言說明。\"\n",
    "\n",
    "print(f\"\\n使用 {model_name} 生成內容...\")\n",
    "try:\n",
    "    response = client.generate(\n",
    "        model=model_name,\n",
    "        prompt=prompt\n",
    "    )\n",
    "    print(\"\\n回應:\")\n",
    "    display(Markdown(response['response']))\n",
    "except Exception as e:\n",
    "    print(f\"生成時發生錯誤: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f934c87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "使用 gemma3:4b 串流生成內容...\n",
      "\n",
      "回應: 好的，這裡有一篇關於資料科學重要性的短文：\n",
      "\n",
      "**資料科學：在數據時代的關鍵**\n",
      "\n",
      "在21世紀，我們正身處一個前所未有的數字時代。每天，全球產生了海量數據，從社交媒體互動到消費行為，再到環境監測和科學研究。 然而，這份數據本身沒有價值。要從數據中提取有意義的信息，做出明智的決策並取得成功，我們需要資料科學。\n",
      "\n",
      "資料科學是一個跨領域學科，結合了統計學、電腦科學和領域專業知識。它使用各種技術和方法來收集、清理、分析和解讀數據，以發現隱藏的模式、趨勢和關係。\n",
      "\n",
      "**資料科學的重要性體現在以下幾個方面：**\n",
      "\n",
      "*   **更好的決策：** 透過深入的數據分析，企業和組織可以更準確地預測趨勢，改善產品和服務，優化運營，並做出更明智的商業決策。\n",
      "*   **創新與開發：** 資料科學驅動了許多創新，例如個性化推薦系統、自動駕駛汽車和新藥研發。\n",
      "*   **問題解決：** 資料科學可以應用於解決各種複雜的問題，例如氣候變化、疾病預防和犯罪預防。\n",
      "*   **提高效率：** 透過數據分析，我們可以識別浪費和無效性，從而提高效率並降低成本。\n",
      "\n",
      "隨著數據量的持續增長，資料科學的地位將變得越來越重要。無論是企業、政府還是研究機構，都需要資料科學家來幫助他們利用數據的力量，實現創新和解決問題。\n",
      "\n",
      "---\n",
      "\n",
      "希望這篇短文對您有幫助！您是否希望我為您修改或擴展這篇文章？\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用流式輸出生成文本\n",
    "model_name = \"gemma3:4b\"  # 使用您有的模型名稱\n",
    "prompt = \"撰寫一個關於資料科學重要性的短文。\"\n",
    "\n",
    "print(f\"\\n使用 {model_name} 串流生成內容...\")\n",
    "print(\"\\n回應: \", end=\"\", flush=True)\n",
    "try:\n",
    "    for chunk in client.generate(\n",
    "        model=model_name,\n",
    "        prompt=prompt,\n",
    "        stream=True\n",
    "    ):\n",
    "        content = chunk['response']\n",
    "        print(content, end=\"\", flush=True)\n",
    "        time.sleep(0.01)  # 小延遲以更好地模擬生成\n",
    "    print(\"\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n生成時發生錯誤: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f3dc7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "與 gemma3:4b 進行對話...\n",
      "\n",
      "助理回應:\n",
      "我是 Gemma，一個由 Google DeepMind 訓練的大型語言模型。我是一個開放權重的模型，可以廣泛地用於各種任務。\n",
      "\n",
      "\n",
      "用戶: 你可以幫助我做什麼？\n",
      "\n",
      "助理回應:\n",
      "我可以做很多事情！以下是一些我能幫你的例子：\n",
      "\n",
      "**文字生成和創作：**\n",
      "\n",
      "*   **寫作:** 我可以幫你寫文章、故事、詩歌、信件、劇本等等。你可以給我一個主題、關鍵字，或者只是一個想法，我會盡力生成文本。\n",
      "*   **總結:** 我可以將長篇文字或文章概括成簡短的摘要。\n",
      "*   **翻譯:** 我可以將文字從一種語言翻譯成另一種語言。\n",
      "*   **內容改寫:** 我可以幫你改寫文字，使其更清晰、更簡潔、更具說服力。\n",
      "*   **生成不同風格的文本:** 比如，你可以要求我用莎士比亞的風格寫一段文字，或者用幽默的風格寫一段文字。\n",
      "\n",
      "**資訊查詢和學習：**\n",
      "\n",
      "*   **回答問題:** 我可以回答你提出的各種問題，即使它們很複雜或開放性很高。\n",
      "*   **提供資訊:** 我可以給你提供各種主題的資訊，比如歷史、科學、文化等等。\n",
      "*   **解釋概念:** 我可以解釋複雜的概念，並用簡單易懂的方式說明。\n",
      "*   **生成學習材料:** 我可以根據你的需求生成學習材料，比如名單、重點、解釋等等。\n",
      "\n",
      "**其他：**\n",
      "\n",
      "*   **創意發想:** 如果你正在進行創意項目，我可以幫助你產生想法。\n",
      "*   **玩遊戲:** 我可以和你玩一些文字遊戲，比如猜謎語、填字遊戲等等。\n",
      "*   **提供建議:** 在某些情況下，我可以給你一些建議，比如旅遊建議、購物建議等等。\n",
      "\n",
      "**重要提示:**\n",
      "\n",
      "*   **我不是完美的:** 我仍然在不斷學習和改進。有時候，我可能會犯錯誤，或者提供不準確的資訊。在使用我的回答時，請務必保持批判性思考，並驗證資訊的準確性。\n",
      "*   **我沒有個人經驗:** 我是基於數據訓練的，沒有自己的情感、觀點或信仰。\n",
      "\n",
      "**總之，只要你提出的要求在我的能力範圍內，我都會盡力幫助你。 你想讓我做些什麼呢？**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 聊天模式示例\n",
    "model_name = \"gemma3:4b\"  # 使用您有的模型名稱\n",
    "\n",
    "print(f\"\\n與 {model_name} 進行對話...\")\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"你好，你能告訴我你是誰嗎？\"\n",
    "    }\n",
    "]\n",
    "\n",
    "try:\n",
    "    response = client.chat(\n",
    "        model=model_name,\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    assistant_message = response['message']['content']\n",
    "    print(\"\\n助理回應:\")\n",
    "    print(assistant_message)\n",
    "    \n",
    "    # 將助理回應添加到對話歷史\n",
    "    messages.append({\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": assistant_message\n",
    "    })\n",
    "    \n",
    "    # 繼續對話\n",
    "    second_question = \"你可以幫助我做什麼？\"\n",
    "    print(f\"\\n用戶: {second_question}\")\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": second_question\n",
    "    })\n",
    "    \n",
    "    response = client.chat(\n",
    "        model=model_name,\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    assistant_message = response['message']['content']\n",
    "    print(\"\\n助理回應:\")\n",
    "    print(assistant_message)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"聊天時發生錯誤: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8f85db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 實現聊天機器人的多輪對話功能\n",
    "def chat_with_model(client, model_name, initial_message=None):\n",
    "    \"\"\"\n",
    "    與指定模型進行交互式聊天\n",
    "    \n",
    "    Args:\n",
    "        client: Ollama客戶端實例\n",
    "        model_name: 要使用的模型名稱\n",
    "        initial_message: 可選的初始訊息\n",
    "    \"\"\"\n",
    "    # 初始化對話歷史\n",
    "    messages = []\n",
    "    \n",
    "    # 如果有初始訊息，添加到對話歷史\n",
    "    if initial_message:\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": initial_message\n",
    "        })\n",
    "        \n",
    "        try:\n",
    "            response = client.chat(model=model_name, messages=messages)\n",
    "            assistant_message = response['message']['content']\n",
    "            print(\"\\n助理回應:\")\n",
    "            print(assistant_message)\n",
    "            \n",
    "            # 將助理回應添加到對話歷史\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": assistant_message\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"聊天時發生錯誤: {e}\")\n",
    "            return\n",
    "    \n",
    "    print(f\"\\n開始與 {model_name} 的對話。輸入 'exit' 或 'quit' 結束對話。\")\n",
    "    \n",
    "    # 開始對話循環\n",
    "    while True:\n",
    "        # 獲取用戶輸入\n",
    "        user_input = input(\"\\n你: \")\n",
    "        \n",
    "        # 檢查是否退出\n",
    "        if user_input.lower() in ['exit', 'quit']:\n",
    "            print(\"對話結束\")\n",
    "            break\n",
    "        \n",
    "        # 添加用戶訊息到對話歷史\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_input\n",
    "        })\n",
    "        \n",
    "        try:\n",
    "            # 獲取模型回應\n",
    "            print(\"模型思考中...\", end=\"\\r\")\n",
    "            response = client.chat(model=model_name, messages=messages)\n",
    "            assistant_message = response['message']['content']\n",
    "            \n",
    "            # 清除思考中的提示\n",
    "            print(\" \" * 20, end=\"\\r\")\n",
    "            \n",
    "            # 顯示助理回應\n",
    "            print(\"\\n助理: \")\n",
    "            print(assistant_message)\n",
    "            \n",
    "            # 將助理回應添加到對話歷史\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": assistant_message\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"聊天時發生錯誤: {e}\")\n",
    "            break\n",
    "    \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a60fb5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab327e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
