{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "471af8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨æª¢æŸ¥ Ollama æœå‹™å™¨é€£æ¥ (http://163.18.22.32:11435)...\n",
      "é€£æ¥æˆåŠŸï¼å¯ç”¨æ¨¡å‹: gemma3:4b\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import sys\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# è¨­ç½® Ollama æœå‹™å™¨åœ°å€\n",
    "OLLAMA_HOST = \"http://163.18.22.32:11435\"\n",
    "ollama.host = OLLAMA_HOST\n",
    "\n",
    "# åœ¨ç¨‹å¼é–‹å§‹æ™‚æª¢æŸ¥é€£æ¥\n",
    "print(f\"æ­£åœ¨æª¢æŸ¥ Ollama æœå‹™å™¨é€£æ¥ ({OLLAMA_HOST})...\")\n",
    "try:\n",
    "    # å˜—è©¦ç²å–å¯ç”¨æ¨¡å‹åˆ—è¡¨ä»¥æ¸¬è©¦é€£æ¥\n",
    "    response = requests.get(f\"{OLLAMA_HOST}/api/tags\")\n",
    "    if response.status_code == 200:\n",
    "        models = response.json()\n",
    "        available_models = [model['name'] for model in models['models']]\n",
    "        print(f\"é€£æ¥æˆåŠŸï¼å¯ç”¨æ¨¡å‹: {', '.join(available_models)}\")\n",
    "    else:\n",
    "        print(f\"é€£æ¥å¤±æ•—ï¼Œæœå‹™å™¨è¿”å›ç‹€æ…‹ç¢¼: {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"ç„¡æ³•é€£æ¥åˆ° Ollama æœå‹™å™¨: {e}\")\n",
    "    print(\"è«‹æª¢æŸ¥:\")\n",
    "    print(\"1. Ollama æœå‹™å™¨æ˜¯å¦æ­£åœ¨é‹è¡Œ\")\n",
    "    print(\"2. ç¶²çµ¡é€£æ¥æ˜¯å¦æ­£å¸¸\")\n",
    "    print(\"3. é˜²ç«ç‰†è¨­ç½®æ˜¯å¦å…è¨±é€£æ¥\")\n",
    "    print(\"4. IP åœ°å€å’Œç«¯å£æ˜¯å¦æ­£ç¢º\")\n",
    "    sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce6946ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ä½¿ç”¨ gemma3:4b ç”Ÿæˆå…§å®¹...\n",
      "\n",
      "å›æ‡‰:\n",
      "å¥½çš„ï¼Œæˆ‘å€‘ä¾†ç”¨ç°¡å–®çš„æ–¹å¼è§£é‡‹å¤§æ•¸æ“šåˆ†æï¼š\n",
      "\n",
      "**æƒ³åƒä¸€ä¸‹ï¼Œä½ æœ‰ä¸€å †è¶…ç´šå¤šçš„æ±è¥¿ï¼Œæ¯”ä½ å¹³å¸¸è™•ç†çš„è³‡æ–™é‚„è¦å¤šå¥½å¹¾ç™¾å€ç”šè‡³ä¸Šåƒå€ã€‚**\n",
      "\n",
      "*   é€™äº›æ±è¥¿å¯ä»¥æ˜¯ï¼šç¶²è·¯ä¸Šæ¯å€‹äººçš„ç€è¦½è¨˜éŒ„ã€è³¼ç‰©ç´€éŒ„ã€ç¤¾ç¾¤åª’é«”ä¸Šçš„ç™¼æ–‡ã€æ„Ÿæ¸¬å™¨æ”¶é›†åˆ°çš„ç’°å¢ƒæ•¸æ“šã€è‚¡ç¥¨äº¤æ˜“ç´€éŒ„ç­‰ç­‰ã€‚\n",
      "*   é€™äº›è³‡æ–™é‡éå¸¸é¾å¤§ï¼Œå‚³çµ±çš„é›»è…¦è»Ÿé«”å’Œæ–¹æ³•è™•ç†èµ·ä¾†ï¼Œå°±åƒåœ¨æ²™ç˜ä¸Šç”¨å‹ºå­èˆ€æ°´ï¼Œéå¸¸æ…¢è€Œä¸”æ•ˆç‡å¾ˆä½ã€‚\n",
      "\n",
      "**å¤§æ•¸æ“šåˆ†æå°±æ˜¯ç”¨ç‰¹åˆ¥çš„å·¥å…·å’Œæ–¹æ³•ï¼Œå»å¾é€™äº›è¶…ç´šå¤šçš„è³‡æ–™è£¡ï¼ŒæŒ–æ˜å‡ºæœ‰ç”¨çš„è³‡è¨Šå’Œè¦å¾‹ã€‚**\n",
      "\n",
      "**æ›´è©³ç´°çš„è§£é‡‹ï¼š**\n",
      "\n",
      "1.  **ã€Œå¤§æ•¸æ“šã€ (Big Data):** æŒ‡çš„æ˜¯è¶…å‡ºå‚³çµ±æ•¸æ“šè™•ç†å·¥å…·å’Œæ–¹æ³•æ‰€èƒ½è™•ç†çš„è³‡æ–™é‡ï¼Œé€šå¸¸åŒ…å«ä»¥ä¸‹å››å€‹ç‰¹å¾µï¼š\n",
      "    *   **Volume (æ•¸é‡):** è³‡æ–™é‡éå¸¸å¤§ã€‚\n",
      "    *   **Velocity (é€Ÿåº¦):** è³‡æ–™ç”¢ç”Ÿå’Œæ›´æ–°çš„é€Ÿåº¦éå¸¸å¿«ã€‚\n",
      "    *   **Variety (å¤šæ¨£æ€§):** è³‡æ–™çš„é¡å‹éå¸¸å¤šï¼Œä¾‹å¦‚æ–‡å­—ã€åœ–ç‰‡ã€å½±ç‰‡ã€æ•¸å­—ç­‰ç­‰ã€‚\n",
      "    *   **Veracity (çœŸå¯¦æ€§):** è³‡æ–™çš„å“è³ªå’Œæº–ç¢ºæ€§å¯èƒ½ä¸ä¸€è‡´ã€‚\n",
      "\n",
      "2.  **åˆ†æçš„ç›®çš„ï¼š** é€éå¤§æ•¸æ“šåˆ†æï¼Œæˆ‘å€‘å¯ä»¥ï¼š\n",
      "    *   **é æ¸¬æœªä¾†:**  ä¾‹å¦‚ï¼Œæ ¹æ“šéå»çš„éŠ·å”®ç´€éŒ„ï¼Œé æ¸¬æœªä¾†å“ªäº›å•†å“æœƒè³£å¾—å¥½ã€‚\n",
      "    *   **æ”¹å–„æ±ºç­–:**  ä¾‹å¦‚ï¼Œæ ¹æ“šé¡§å®¢çš„ç€è¦½è¡Œç‚ºï¼Œèª¿æ•´ç”¢å“æ¨è–¦ç­–ç•¥ã€‚\n",
      "    *   **ç™¼ç¾éš±è—çš„é—œä¿‚:** ä¾‹å¦‚ï¼Œæ‰¾å‡ºå“ªäº›å› ç´ æœƒå°è‡´æŸäº›ç–¾ç—…çš„ç™¼ç”Ÿã€‚\n",
      "    *   **å„ªåŒ–æ¥­å‹™æµç¨‹:**  ä¾‹å¦‚ï¼Œæ ¹æ“šäº¤é€šæµé‡æ•¸æ“šï¼Œå„ªåŒ–äº¤é€šè·¯ç·šã€‚\n",
      "\n",
      "3.  **ä½¿ç”¨çš„å·¥å…·å’Œæ–¹æ³•ï¼š** å¤§æ•¸æ“šåˆ†æéœ€è¦ç”¨åˆ°ä¸€äº›ç‰¹æ®Šçš„å·¥å…·å’Œæ–¹æ³•ï¼Œä¾‹å¦‚ï¼š\n",
      "    *   **æ©Ÿå™¨å­¸ç¿’:**  è®“é›»è…¦è‡ªå·±å­¸ç¿’è³‡æ–™ä¸­çš„è¦å¾‹ï¼Œä¸¦æ ¹æ“šé€™äº›è¦å¾‹é€²è¡Œé æ¸¬æˆ–åˆ†é¡ã€‚\n",
      "    *   **æ•¸æ“šæŒ–æ˜:**  å¾è³‡æ–™ä¸­ç™¼ç¾æœ‰åƒ¹å€¼çš„æ¨¡å¼å’Œé—œä¿‚ã€‚\n",
      "    *   **é›²è¨ˆç®—:**  æä¾›å¤§æ•¸æ“šåˆ†ææ‰€éœ€çš„è¨ˆç®—èƒ½åŠ›å’Œå„²å­˜ç©ºé–“ã€‚\n",
      "\n",
      "**ç°¡å–®ä¾†èªªï¼Œå¤§æ•¸æ“šåˆ†æå°±æ˜¯æŠŠå¤§é‡ã€å¤šæ¨£çš„æ•¸æ“šè®Šæˆæœ‰ç”¨çš„ä¿¡æ¯ï¼Œå¹«åŠ©æˆ‘å€‘åšå‡ºæ›´å¥½çš„æ±ºç­–ï¼**\n",
      "\n",
      "å¸Œæœ›é€™å€‹è§£é‡‹å°ä½ æœ‰å¹«åŠ©ï¼\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨ requests ç›´æ¥èª¿ç”¨ Ollama API ç”Ÿæˆæ–‡æœ¬\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# è¨­ç½® Ollama æœå‹™å™¨åœ°å€\n",
    "OLLAMA_HOST = \"http://163.18.22.32:11435\"\n",
    "\n",
    "# ç°¡å–®çš„æ–‡æœ¬ç”Ÿæˆç¤ºä¾‹\n",
    "model_name = \"gemma3:4b\"  # ä½¿ç”¨æ‚¨æœ‰çš„æ¨¡å‹åç¨±\n",
    "prompt = \"è§£é‡‹ä»€éº¼æ˜¯å¤§æ•¸æ“šåˆ†æï¼Ÿè«‹ç”¨ç°¡å–®çš„èªè¨€èªªæ˜ã€‚\"\n",
    "\n",
    "print(f\"\\nä½¿ç”¨ {model_name} ç”Ÿæˆå…§å®¹...\")\n",
    "try:\n",
    "    # æ§‹å»º API è«‹æ±‚\n",
    "    url = f\"{OLLAMA_HOST}/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    # ç™¼é€è«‹æ±‚\n",
    "    response = requests.post(url, json=payload)\n",
    "    \n",
    "    # æª¢æŸ¥éŸ¿æ‡‰\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        print(\"\\nå›æ‡‰:\")\n",
    "        print(result['response'])\n",
    "    else:\n",
    "        print(f\"API è¿”å›éŒ¯èª¤: {response.status_code}\")\n",
    "        print(response.text)\n",
    "except Exception as e:\n",
    "    print(f\"ç”Ÿæˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9316914a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "èˆ‡ gemma3:4b é€²è¡Œå°è©±...\n",
      "\n",
      "åŠ©ç†å›æ‡‰:\n",
      "æˆ‘æ˜¯Google DeepMindè¨“ç·´çš„å¤§å‹èªè¨€æ¨¡å‹ï¼Œå«åšGemmaã€‚ \n",
      "\n",
      "æˆ‘æ˜¯ä¸€å€‹é–‹æ”¾æ¬Šé‡çš„æ¨¡å‹ï¼Œå¯ä»¥èˆ‡ä½ é€²è¡Œå°è©±ï¼Œä¸¦æ ¹æ“šä½ çš„æŒ‡ç¤ºç”Ÿæˆæ–‡æœ¬ã€‚ \n",
      "\n",
      "ç°¡è€Œè¨€ä¹‹ï¼Œæˆ‘æ˜¯ä¸€å€‹äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼ ğŸ˜Š\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨ requests ç›´æ¥èª¿ç”¨ Ollama API é€²è¡ŒèŠå¤©\n",
    "import requests\n",
    "\n",
    "# è¨­ç½® Ollama æœå‹™å™¨åœ°å€\n",
    "OLLAMA_HOST = \"http://163.18.22.32:11435\"\n",
    "\n",
    "# èŠå¤©ç¤ºä¾‹\n",
    "model_name = \"gemma3:4b\"  # ä½¿ç”¨æ‚¨æœ‰çš„æ¨¡å‹åç¨±\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"ä½ å¥½ï¼Œä½ èƒ½å‘Šè¨´æˆ‘ä½ æ˜¯èª°å—ï¼Ÿ\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"\\nèˆ‡ {model_name} é€²è¡Œå°è©±...\")\n",
    "try:\n",
    "    # æ§‹å»º API è«‹æ±‚\n",
    "    url = f\"{OLLAMA_HOST}/api/chat\"\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    # ç™¼é€è«‹æ±‚\n",
    "    response = requests.post(url, json=payload)\n",
    "    \n",
    "    # æª¢æŸ¥éŸ¿æ‡‰\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        assistant_message = result['message']['content']\n",
    "        print(\"\\nåŠ©ç†å›æ‡‰:\")\n",
    "        print(assistant_message)\n",
    "    else:\n",
    "        print(f\"API è¿”å›éŒ¯èª¤: {response.status_code}\")\n",
    "        print(response.text)\n",
    "except Exception as e:\n",
    "    print(f\"èŠå¤©æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69c01caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ä½¿ç”¨ gemma3:4b ä¸²æµç”Ÿæˆå…§å®¹...\n",
      "\n",
      "å›æ‡‰: å¥½çš„ï¼Œä»¥ä¸‹æ˜¯ä¸€ç¯‡é—œæ–¼è³‡æ–™ç§‘å­¸é‡è¦æ€§çš„çŸ­æ–‡ï¼š\n",
      "\n",
      "**è³‡æ–™ç§‘å­¸ï¼šæ•¸æ“šé©…å‹•çš„æœªä¾†**\n",
      "\n",
      "åœ¨ç•¶ä»Šæ™‚ä»£ï¼Œæˆ‘å€‘è¢«ç„¡æ•¸æ•¸æ“šæ‰€æ·¹æ²’ã€‚å¾æ¶ˆè²»è€…çš„è³¼è²·è¨˜éŒ„åˆ°ç¶²è·¯ç”¨æˆ¶çš„ç€è¦½è¡Œç‚ºï¼Œå¾å¤©æ°£æ¨¡å¼åˆ°ç”Ÿç‰©æ•¸æ“šï¼Œæ•¸æ“šç„¡æ‰€ä¸åœ¨ã€‚ç„¶è€Œï¼Œé€™äº›æ•¸æ“šæœ¬èº«ä¸¦æ²’æœ‰åƒ¹å€¼ï¼Œå®ƒå€‘åªæœ‰åœ¨ç¶“éåˆ†æå’Œç†è§£å¾Œï¼Œæ‰èƒ½è½‰åŒ–ç‚ºæœ‰ç”¨çš„æ´è¦‹ï¼Œä¸¦æ¨å‹•å„ç¨®è¡Œæ¥­çš„å‰µæ–°å’Œç™¼å±•ã€‚é€™å°±æ˜¯è³‡æ–™ç§‘å­¸çš„é‡è¦æ€§æ‰€åœ¨ã€‚\n",
      "\n",
      "è³‡æ–™ç§‘å­¸æ˜¯ä¸€å€‹è·¨é ˜åŸŸçš„å­¸ç§‘ï¼Œå®ƒçµåˆäº†çµ±è¨ˆå­¸ã€æ©Ÿå™¨å­¸ç¿’ã€æ•¸æ“šæŒ–æ˜ã€è³‡è¨Šå·¥ç¨‹å’Œå•†æ¥­çŸ¥è­˜ï¼Œæ—¨åœ¨å¾å¤§é‡æ•¸æ“šä¸­æå–çŸ¥è­˜å’Œè¶¨å‹¢ã€‚è³‡æ–™ç§‘å­¸å®¶ä½¿ç”¨å„ç¨®å·¥å…·å’ŒæŠ€è¡“ï¼Œä¾‹å¦‚æ©Ÿå™¨å­¸ç¿’ç®—æ³•ã€æ•¸æ“šåº«å’Œå¤§æ•¸æ“šå¹³å°ï¼Œä¾†åˆ†ææ•¸æ“šï¼Œå»ºç«‹æ¨¡å‹ï¼Œä¸¦é æ¸¬æœªä¾†è¶¨å‹¢ã€‚\n",
      "\n",
      "è³‡æ–™ç§‘å­¸çš„é‡è¦æ€§é«”ç¾åœ¨ä»¥ä¸‹å¹¾å€‹æ–¹é¢ï¼š\n",
      "\n",
      "* **æ”¹å–„æ±ºç­–ï¼š** é€éæ•¸æ“šåˆ†æï¼Œä¼æ¥­å’Œçµ„ç¹”å¯ä»¥åšå‡ºæ›´æ˜æ™ºçš„æ±ºç­–ï¼Œå„ªåŒ–ç‡Ÿé‹æ•ˆç‡ï¼Œé™ä½é¢¨éšªã€‚\n",
      "* **å‰µæ–°ç”¢å“èˆ‡æœå‹™ï¼š**  è³‡æ–™ç§‘å­¸å¯ä»¥å¹«åŠ©ä¼æ¥­äº†è§£æ¶ˆè²»è€…çš„éœ€æ±‚å’Œåå¥½ï¼Œå¾è€Œé–‹ç™¼å‡ºæ›´ç¬¦åˆå¸‚å ´éœ€æ±‚çš„æ–°ç”¢å“å’Œæœå‹™ã€‚\n",
      "* **å„ªåŒ–æµç¨‹ï¼š**  é€éæ•¸æ“šåˆ†æï¼Œä¼æ¥­å¯ä»¥è­˜åˆ¥æµç¨‹ä¸­çš„ç“¶é ¸ï¼Œä¸¦åŠ ä»¥æ”¹é€²ï¼Œæé«˜æ•ˆç‡å’Œé™ä½æˆæœ¬ã€‚\n",
      "* **é æ¸¬è¶¨å‹¢ï¼š**  è³‡æ–™ç§‘å­¸å¯ä»¥å¹«åŠ©æˆ‘å€‘é æ¸¬å¸‚å ´è¶¨å‹¢ã€æ¶ˆè²»è€…è¡Œç‚ºå’Œæ½›åœ¨çš„é¢¨éšªï¼Œå¾è€Œåšå‡ºæ›´æœ‰æ•ˆçš„æ‡‰å°æªæ–½ã€‚\n",
      "\n",
      "éš¨è‘—å¤§æ•¸æ“šæ™‚ä»£çš„ä¾†è‡¨ï¼Œè³‡æ–™ç§‘å­¸å°‡åœ¨å„è¡Œå„æ¥­æ‰®æ¼”è¶Šä¾†è¶Šé‡è¦çš„è§’è‰²ã€‚å®ƒä¸åƒ…åƒ…æ˜¯ä¸€ç¨®æŠ€è¡“ï¼Œæ›´æ˜¯ä¸€ç¨®æ€ç¶­æ–¹å¼ï¼Œä¸€ç¨®ä»¥æ•¸æ“šç‚ºåŸºç¤çš„è§£æ±ºå•é¡Œçš„å…¨æ–°æ–¹æ³•ã€‚é‚£äº›èƒ½å¤ å–„ç”¨è³‡æ–™ç§‘å­¸çš„äººï¼Œå°‡åœ¨æœªä¾†æ“æœ‰æ›´å¤§çš„ç«¶çˆ­å„ªå‹¢ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "å¸Œæœ›é€™ç¯‡çŸ­æ–‡å°æ‚¨æœ‰æ‰€å¹«åŠ©ï¼æ‚¨æƒ³è®“æˆ‘ä¿®æ”¹æˆ–èª¿æ•´å“ªäº›æ–¹é¢å‘¢ï¼Ÿä¾‹å¦‚ï¼Œæˆ‘å¯ä»¥èª¿æ•´é•·åº¦ï¼Œæˆ–è‘—å¢åŠ ä¸€äº›ç‰¹å®šçš„æ‡‰ç”¨å ´æ™¯ã€‚\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨ requests ç›´æ¥èª¿ç”¨ Ollama API é€²è¡Œä¸²æµç”Ÿæˆ\n",
    "import requests\n",
    "\n",
    "# è¨­ç½® Ollama æœå‹™å™¨åœ°å€\n",
    "OLLAMA_HOST = \"http://163.18.22.32:11435\"\n",
    "\n",
    "# ä¸²æµç”Ÿæˆç¤ºä¾‹\n",
    "model_name = \"gemma3:4b\"  # ä½¿ç”¨æ‚¨æœ‰çš„æ¨¡å‹åç¨±\n",
    "prompt = \"æ’°å¯«ä¸€å€‹é—œæ–¼è³‡æ–™ç§‘å­¸é‡è¦æ€§çš„çŸ­æ–‡ã€‚\"\n",
    "\n",
    "print(f\"\\nä½¿ç”¨ {model_name} ä¸²æµç”Ÿæˆå…§å®¹...\")\n",
    "print(\"\\nå›æ‡‰: \", end=\"\", flush=True)\n",
    "try:\n",
    "    # æ§‹å»º API è«‹æ±‚\n",
    "    url = f\"{OLLAMA_HOST}/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": True\n",
    "    }\n",
    "    \n",
    "    # ç™¼é€ä¸²æµè«‹æ±‚\n",
    "    with requests.post(url, json=payload, stream=True) as response:\n",
    "        if response.status_code == 200:\n",
    "            for line in response.iter_lines():\n",
    "                if line:\n",
    "                    # è§£æ JSON æ•¸æ“š\n",
    "                    data = json.loads(line.decode('utf-8'))\n",
    "                    if 'response' in data:\n",
    "                        print(data['response'], end=\"\", flush=True)\n",
    "            print(\"\\n\")\n",
    "        else:\n",
    "            print(f\"\\nAPI è¿”å›éŒ¯èª¤: {response.status_code}\")\n",
    "            print(response.text)\n",
    "except Exception as e:\n",
    "    print(f\"\\nç”Ÿæˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625cac2d",
   "metadata": {},
   "source": [
    "# å¦ä¸€æ–¹å¼ä½¿ç”¨chat() generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd9d3279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "# è¨­ç½®é ç¨‹ Ollama æ¨¡å‹çš„åŸºç¤ URL\n",
    "REMOTE_OLLAMA_URL = \"http://163.18.22.32:11435\"\n",
    "# å‰µå»ºå®¢æˆ¶ç«¯å¯¦ä¾‹\n",
    "client = ollama.Client(host=REMOTE_OLLAMA_URL)\n",
    "\n",
    "# è¨­ç½®è¦ä½¿ç”¨çš„æ¨¡å‹åç¨±\n",
    "model_name = \"gemma3:4b\" # é»˜èªæ¨¡å‹åç¨±\n",
    "#model_name = \"llama3:latest\"\n",
    "#model_name = \"deepseek-r1:7b\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f7cb15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# This is a markdown heading\n",
       "\n",
       "- This is a bullet point\n",
       "- Another bullet point\n",
       "\n",
       "**Bold text** and *italic text*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def display_markdown(text):\n",
    "    \"\"\"\n",
    "    Display text as rendered markdown in the notebook\n",
    "    \n",
    "    Args:\n",
    "        text (str): The markdown text to render\n",
    "    \"\"\"\n",
    "    display(Markdown(text))\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Example usage\n",
    "example_text = \"\"\"\n",
    "# This is a markdown heading\n",
    "\n",
    "- This is a bullet point\n",
    "- Another bullet point\n",
    "\n",
    "**Bold text** and *italic text*\n",
    "\"\"\"\n",
    "display_markdown(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89c9e996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# This is a markdown heading\n",
       "\n",
       "- This is a bullet point\n",
       "- Another bullet point\n",
       "\n",
       "**Bold text** and *italic text*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(example_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "650a2be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# This is a markdown heading\n",
       "\n",
       "- This is a bullet point\n",
       "- Another bullet point\n",
       "\n",
       "**Bold text** and *italic text*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e6c14d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ä½¿ç”¨ gemma3:4b ç”Ÿæˆå…§å®¹...\n",
      "\n",
      "å›æ‡‰:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "å¥½çš„ï¼Œè®“æˆ‘ç”¨ç°¡å–®çš„èªè¨€è§£é‡‹å¤§æ•¸æ“šåˆ†æï¼š\n",
       "\n",
       "**æƒ³åƒä¸€ä¸‹ï¼Œä½ æœ‰ä¸€å€‹è¶…ç´šå¤§çš„å„²è—å®¤ï¼Œè£¡é¢å¡æ»¿äº†å„ç¨®å„æ¨£çš„è³‡è¨Šã€‚** é€™äº›è³‡è¨Šå¯èƒ½ä¾†è‡ªï¼š\n",
       "\n",
       "*   ç¶²ç«™ä¸Šçš„ç€è¦½ç´€éŒ„\n",
       "*   æ‰‹æ©ŸAppçš„ä½¿ç”¨æƒ…æ³\n",
       "*   ç¤¾äº¤åª’é«”ä¸Šçš„è¨è«–\n",
       "*   éŠ·å”®è¨˜éŒ„\n",
       "*   å¤©æ°£æ•¸æ“š\n",
       "*   ç”šè‡³æ˜¯æ„Ÿæ¸¬å™¨å¾å„ç¨®è¨­å‚™ç™¼é€çš„è¨Šæ¯\n",
       "\n",
       "**é€™ç¨®æƒ…æ³ä¸‹ï¼Œæˆ‘å€‘å°±é€²å…¥äº†â€œå¤§æ•¸æ“šâ€çš„ç¯„åœã€‚** å› ç‚ºè³‡è¨Šé‡å¯¦åœ¨å¤ªå¤§äº†ï¼Œå‚³çµ±çš„é›»è…¦æˆ–åˆ†ææ–¹æ³•æ ¹æœ¬ç„¡æ³•è™•ç†ã€‚\n",
       "\n",
       "**å¤§æ•¸æ“šåˆ†æå°±æ˜¯æŒ‡åˆ©ç”¨ç‰¹æ®Šçš„æŠ€è¡“å’Œæ–¹æ³•ï¼Œå¾é€™äº›æµ·é‡ã€å¤šæ¨£ã€å¿«é€Ÿè®Šå‹•çš„æ•¸æ“šä¸­ï¼ŒæŒ–æ˜å‡ºæœ‰ç”¨çš„è³‡è¨Šå’Œè¶¨å‹¢ã€‚**\n",
       "\n",
       "**ç°¡å–®ä¾†èªªï¼Œå°±æ˜¯ï¼š**\n",
       "\n",
       "1.  **æ”¶é›†ï¼š** æ”¶é›†å¤§é‡çš„æ•¸æ“šã€‚\n",
       "2.  **è™•ç†ï¼š** æ¸…ç†å’Œæ•´ç†é€™äº›æ•¸æ“šï¼Œè®“å®ƒè®Šå¾—æœ‰æ„ç¾©ã€‚\n",
       "3.  **åˆ†æï¼š**  é‹ç”¨æŠ€è¡“ï¼ˆåƒæ˜¯æ©Ÿå™¨å­¸ç¿’ï¼‰ä¾†æ‰¾å‡ºæ•¸æ“šä¸­çš„æ¨¡å¼ã€é—œä¿‚å’Œè¶¨å‹¢ã€‚\n",
       "4.  **æ‡‰ç”¨ï¼š**  åˆ©ç”¨åˆ†æçµæœï¼Œå¹«åŠ©ä¼æ¥­æˆ–çµ„ç¹”åšå‡ºæ›´å¥½çš„æ±ºç­–ï¼Œä¾‹å¦‚ï¼š\n",
       "    *   **é›¶å”®ï¼š**  äº†è§£é¡§å®¢å–œæ­¡ä»€éº¼ã€åœ¨å“ªè£¡è³¼è²·ã€ä»¥åŠå¦‚ä½•æä¾›æ›´å€‹äººåŒ–çš„è³¼ç‰©é«”é©—ã€‚\n",
       "    *   **é†«ç™‚ï¼š**  æ‰¾å‡ºç–¾ç—…çš„æ—©æœŸå¾µå…†ã€æ”¹å–„æ²»ç™‚æ–¹æ¡ˆã€‚\n",
       "    *   **äº¤é€šï¼š**  å„ªåŒ–äº¤é€šæµé‡ã€æ¸›å°‘æ“å µã€‚\n",
       "\n",
       "**é—œéµçš„æŠ€è¡“ï¼š**\n",
       "\n",
       "*   **æ©Ÿå™¨å­¸ç¿’ï¼š**  è®“é›»è…¦å¯ä»¥è‡ªå·±å¾æ•¸æ“šä¸­å­¸ç¿’ï¼Œä¸¦é æ¸¬æœªä¾†è¶¨å‹¢ã€‚\n",
       "*   **æ•¸æ“šæŒ–æ˜ï¼š**  å¾æ•¸æ“šä¸­ç™¼ç¾éš±è—çš„æ¨¡å¼ã€‚\n",
       "*   **é›²è¨ˆç®—ï¼š**  æä¾›å„²å­˜å’Œè™•ç†å¤§æ•¸æ“šçš„å¹³å°ã€‚\n",
       "\n",
       "**ç¸½ä¹‹ï¼Œå¤§æ•¸æ“šåˆ†æä¸æ˜¯ç°¡å–®çš„çµ±è¨ˆï¼Œè€Œæ˜¯åˆ©ç”¨ç§‘æŠ€ï¼Œå¾æµ·é‡æ•¸æ“šä¸­å°‹æ‰¾çœŸæ­£æœ‰åƒ¹å€¼çš„è³‡è¨Šã€‚**\n",
       "\n",
       "å¸Œæœ›é€™å€‹è§£é‡‹å°æ‚¨æœ‰å¹«åŠ©ï¼"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ç°¡å–®çš„æ–‡æœ¬ç”Ÿæˆç¤ºä¾‹\n",
    "model_name = \"gemma3:4b\"  # ä½¿ç”¨æ‚¨æœ‰çš„æ¨¡å‹åç¨±\n",
    "prompt = \"è§£é‡‹ä»€éº¼æ˜¯å¤§æ•¸æ“šåˆ†æï¼Ÿè«‹ç”¨ç°¡å–®çš„èªè¨€èªªæ˜ã€‚\"\n",
    "\n",
    "print(f\"\\nä½¿ç”¨ {model_name} ç”Ÿæˆå…§å®¹...\")\n",
    "try:\n",
    "    response = client.generate(\n",
    "        model=model_name,\n",
    "        prompt=prompt\n",
    "    )\n",
    "    print(\"\\nå›æ‡‰:\")\n",
    "    display(Markdown(response['response']))\n",
    "except Exception as e:\n",
    "    print(f\"ç”Ÿæˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f934c87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ä½¿ç”¨ gemma3:4b ä¸²æµç”Ÿæˆå…§å®¹...\n",
      "\n",
      "å›æ‡‰: å¥½çš„ï¼Œé€™è£¡æœ‰ä¸€ç¯‡é—œæ–¼è³‡æ–™ç§‘å­¸é‡è¦æ€§çš„çŸ­æ–‡ï¼š\n",
      "\n",
      "**è³‡æ–™ç§‘å­¸ï¼šåœ¨æ•¸æ“šæ™‚ä»£çš„é—œéµ**\n",
      "\n",
      "åœ¨21ä¸–ç´€ï¼Œæˆ‘å€‘æ­£èº«è™•ä¸€å€‹å‰æ‰€æœªæœ‰çš„æ•¸å­—æ™‚ä»£ã€‚æ¯å¤©ï¼Œå…¨çƒç”¢ç”Ÿäº†æµ·é‡æ•¸æ“šï¼Œå¾ç¤¾äº¤åª’é«”äº’å‹•åˆ°æ¶ˆè²»è¡Œç‚ºï¼Œå†åˆ°ç’°å¢ƒç›£æ¸¬å’Œç§‘å­¸ç ”ç©¶ã€‚ ç„¶è€Œï¼Œé€™ä»½æ•¸æ“šæœ¬èº«æ²’æœ‰åƒ¹å€¼ã€‚è¦å¾æ•¸æ“šä¸­æå–æœ‰æ„ç¾©çš„ä¿¡æ¯ï¼Œåšå‡ºæ˜æ™ºçš„æ±ºç­–ä¸¦å–å¾—æˆåŠŸï¼Œæˆ‘å€‘éœ€è¦è³‡æ–™ç§‘å­¸ã€‚\n",
      "\n",
      "è³‡æ–™ç§‘å­¸æ˜¯ä¸€å€‹è·¨é ˜åŸŸå­¸ç§‘ï¼Œçµåˆäº†çµ±è¨ˆå­¸ã€é›»è…¦ç§‘å­¸å’Œé ˜åŸŸå°ˆæ¥­çŸ¥è­˜ã€‚å®ƒä½¿ç”¨å„ç¨®æŠ€è¡“å’Œæ–¹æ³•ä¾†æ”¶é›†ã€æ¸…ç†ã€åˆ†æå’Œè§£è®€æ•¸æ“šï¼Œä»¥ç™¼ç¾éš±è—çš„æ¨¡å¼ã€è¶¨å‹¢å’Œé—œä¿‚ã€‚\n",
      "\n",
      "**è³‡æ–™ç§‘å­¸çš„é‡è¦æ€§é«”ç¾åœ¨ä»¥ä¸‹å¹¾å€‹æ–¹é¢ï¼š**\n",
      "\n",
      "*   **æ›´å¥½çš„æ±ºç­–ï¼š** é€éæ·±å…¥çš„æ•¸æ“šåˆ†æï¼Œä¼æ¥­å’Œçµ„ç¹”å¯ä»¥æ›´æº–ç¢ºåœ°é æ¸¬è¶¨å‹¢ï¼Œæ”¹å–„ç”¢å“å’Œæœå‹™ï¼Œå„ªåŒ–é‹ç‡Ÿï¼Œä¸¦åšå‡ºæ›´æ˜æ™ºçš„å•†æ¥­æ±ºç­–ã€‚\n",
      "*   **å‰µæ–°èˆ‡é–‹ç™¼ï¼š** è³‡æ–™ç§‘å­¸é©…å‹•äº†è¨±å¤šå‰µæ–°ï¼Œä¾‹å¦‚å€‹æ€§åŒ–æ¨è–¦ç³»çµ±ã€è‡ªå‹•é§•é§›æ±½è»Šå’Œæ–°è—¥ç ”ç™¼ã€‚\n",
      "*   **å•é¡Œè§£æ±ºï¼š** è³‡æ–™ç§‘å­¸å¯ä»¥æ‡‰ç”¨æ–¼è§£æ±ºå„ç¨®è¤‡é›œçš„å•é¡Œï¼Œä¾‹å¦‚æ°£å€™è®ŠåŒ–ã€ç–¾ç—…é é˜²å’ŒçŠ¯ç½ªé é˜²ã€‚\n",
      "*   **æé«˜æ•ˆç‡ï¼š** é€éæ•¸æ“šåˆ†æï¼Œæˆ‘å€‘å¯ä»¥è­˜åˆ¥æµªè²»å’Œç„¡æ•ˆæ€§ï¼Œå¾è€Œæé«˜æ•ˆç‡ä¸¦é™ä½æˆæœ¬ã€‚\n",
      "\n",
      "éš¨è‘—æ•¸æ“šé‡çš„æŒçºŒå¢é•·ï¼Œè³‡æ–™ç§‘å­¸çš„åœ°ä½å°‡è®Šå¾—è¶Šä¾†è¶Šé‡è¦ã€‚ç„¡è«–æ˜¯ä¼æ¥­ã€æ”¿åºœé‚„æ˜¯ç ”ç©¶æ©Ÿæ§‹ï¼Œéƒ½éœ€è¦è³‡æ–™ç§‘å­¸å®¶ä¾†å¹«åŠ©ä»–å€‘åˆ©ç”¨æ•¸æ“šçš„åŠ›é‡ï¼Œå¯¦ç¾å‰µæ–°å’Œè§£æ±ºå•é¡Œã€‚\n",
      "\n",
      "---\n",
      "\n",
      "å¸Œæœ›é€™ç¯‡çŸ­æ–‡å°æ‚¨æœ‰å¹«åŠ©ï¼æ‚¨æ˜¯å¦å¸Œæœ›æˆ‘ç‚ºæ‚¨ä¿®æ”¹æˆ–æ“´å±•é€™ç¯‡æ–‡ç« ï¼Ÿ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨æµå¼è¼¸å‡ºç”Ÿæˆæ–‡æœ¬\n",
    "model_name = \"gemma3:4b\"  # ä½¿ç”¨æ‚¨æœ‰çš„æ¨¡å‹åç¨±\n",
    "prompt = \"æ’°å¯«ä¸€å€‹é—œæ–¼è³‡æ–™ç§‘å­¸é‡è¦æ€§çš„çŸ­æ–‡ã€‚\"\n",
    "\n",
    "print(f\"\\nä½¿ç”¨ {model_name} ä¸²æµç”Ÿæˆå…§å®¹...\")\n",
    "print(\"\\nå›æ‡‰: \", end=\"\", flush=True)\n",
    "try:\n",
    "    for chunk in client.generate(\n",
    "        model=model_name,\n",
    "        prompt=prompt,\n",
    "        stream=True\n",
    "    ):\n",
    "        content = chunk['response']\n",
    "        print(content, end=\"\", flush=True)\n",
    "        time.sleep(0.01)  # å°å»¶é²ä»¥æ›´å¥½åœ°æ¨¡æ“¬ç”Ÿæˆ\n",
    "    print(\"\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nç”Ÿæˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f3dc7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "èˆ‡ gemma3:4b é€²è¡Œå°è©±...\n",
      "\n",
      "åŠ©ç†å›æ‡‰:\n",
      "æˆ‘æ˜¯ Gemmaï¼Œä¸€å€‹ç”± Google DeepMind è¨“ç·´çš„å¤§å‹èªè¨€æ¨¡å‹ã€‚æˆ‘æ˜¯ä¸€å€‹é–‹æ”¾æ¬Šé‡çš„æ¨¡å‹ï¼Œå¯ä»¥å»£æ³›åœ°ç”¨æ–¼å„ç¨®ä»»å‹™ã€‚\n",
      "\n",
      "\n",
      "ç”¨æˆ¶: ä½ å¯ä»¥å¹«åŠ©æˆ‘åšä»€éº¼ï¼Ÿ\n",
      "\n",
      "åŠ©ç†å›æ‡‰:\n",
      "æˆ‘å¯ä»¥åšå¾ˆå¤šäº‹æƒ…ï¼ä»¥ä¸‹æ˜¯ä¸€äº›æˆ‘èƒ½å¹«ä½ çš„ä¾‹å­ï¼š\n",
      "\n",
      "**æ–‡å­—ç”Ÿæˆå’Œå‰µä½œï¼š**\n",
      "\n",
      "*   **å¯«ä½œ:** æˆ‘å¯ä»¥å¹«ä½ å¯«æ–‡ç« ã€æ•…äº‹ã€è©©æ­Œã€ä¿¡ä»¶ã€åŠ‡æœ¬ç­‰ç­‰ã€‚ä½ å¯ä»¥çµ¦æˆ‘ä¸€å€‹ä¸»é¡Œã€é—œéµå­—ï¼Œæˆ–è€…åªæ˜¯ä¸€å€‹æƒ³æ³•ï¼Œæˆ‘æœƒç›¡åŠ›ç”Ÿæˆæ–‡æœ¬ã€‚\n",
      "*   **ç¸½çµ:** æˆ‘å¯ä»¥å°‡é•·ç¯‡æ–‡å­—æˆ–æ–‡ç« æ¦‚æ‹¬æˆç°¡çŸ­çš„æ‘˜è¦ã€‚\n",
      "*   **ç¿»è­¯:** æˆ‘å¯ä»¥å°‡æ–‡å­—å¾ä¸€ç¨®èªè¨€ç¿»è­¯æˆå¦ä¸€ç¨®èªè¨€ã€‚\n",
      "*   **å…§å®¹æ”¹å¯«:** æˆ‘å¯ä»¥å¹«ä½ æ”¹å¯«æ–‡å­—ï¼Œä½¿å…¶æ›´æ¸…æ™°ã€æ›´ç°¡æ½”ã€æ›´å…·èªªæœåŠ›ã€‚\n",
      "*   **ç”Ÿæˆä¸åŒé¢¨æ ¼çš„æ–‡æœ¬:** æ¯”å¦‚ï¼Œä½ å¯ä»¥è¦æ±‚æˆ‘ç”¨èå£«æ¯”äºçš„é¢¨æ ¼å¯«ä¸€æ®µæ–‡å­—ï¼Œæˆ–è€…ç”¨å¹½é»˜çš„é¢¨æ ¼å¯«ä¸€æ®µæ–‡å­—ã€‚\n",
      "\n",
      "**è³‡è¨ŠæŸ¥è©¢å’Œå­¸ç¿’ï¼š**\n",
      "\n",
      "*   **å›ç­”å•é¡Œ:** æˆ‘å¯ä»¥å›ç­”ä½ æå‡ºçš„å„ç¨®å•é¡Œï¼Œå³ä½¿å®ƒå€‘å¾ˆè¤‡é›œæˆ–é–‹æ”¾æ€§å¾ˆé«˜ã€‚\n",
      "*   **æä¾›è³‡è¨Š:** æˆ‘å¯ä»¥çµ¦ä½ æä¾›å„ç¨®ä¸»é¡Œçš„è³‡è¨Šï¼Œæ¯”å¦‚æ­·å²ã€ç§‘å­¸ã€æ–‡åŒ–ç­‰ç­‰ã€‚\n",
      "*   **è§£é‡‹æ¦‚å¿µ:** æˆ‘å¯ä»¥è§£é‡‹è¤‡é›œçš„æ¦‚å¿µï¼Œä¸¦ç”¨ç°¡å–®æ˜“æ‡‚çš„æ–¹å¼èªªæ˜ã€‚\n",
      "*   **ç”Ÿæˆå­¸ç¿’ææ–™:** æˆ‘å¯ä»¥æ ¹æ“šä½ çš„éœ€æ±‚ç”Ÿæˆå­¸ç¿’ææ–™ï¼Œæ¯”å¦‚åå–®ã€é‡é»ã€è§£é‡‹ç­‰ç­‰ã€‚\n",
      "\n",
      "**å…¶ä»–ï¼š**\n",
      "\n",
      "*   **å‰µæ„ç™¼æƒ³:** å¦‚æœä½ æ­£åœ¨é€²è¡Œå‰µæ„é …ç›®ï¼Œæˆ‘å¯ä»¥å¹«åŠ©ä½ ç”¢ç”Ÿæƒ³æ³•ã€‚\n",
      "*   **ç©éŠæˆ²:** æˆ‘å¯ä»¥å’Œä½ ç©ä¸€äº›æ–‡å­—éŠæˆ²ï¼Œæ¯”å¦‚çŒœè¬èªã€å¡«å­—éŠæˆ²ç­‰ç­‰ã€‚\n",
      "*   **æä¾›å»ºè­°:** åœ¨æŸäº›æƒ…æ³ä¸‹ï¼Œæˆ‘å¯ä»¥çµ¦ä½ ä¸€äº›å»ºè­°ï¼Œæ¯”å¦‚æ—…éŠå»ºè­°ã€è³¼ç‰©å»ºè­°ç­‰ç­‰ã€‚\n",
      "\n",
      "**é‡è¦æç¤º:**\n",
      "\n",
      "*   **æˆ‘ä¸æ˜¯å®Œç¾çš„:** æˆ‘ä»ç„¶åœ¨ä¸æ–·å­¸ç¿’å’Œæ”¹é€²ã€‚æœ‰æ™‚å€™ï¼Œæˆ‘å¯èƒ½æœƒçŠ¯éŒ¯èª¤ï¼Œæˆ–è€…æä¾›ä¸æº–ç¢ºçš„è³‡è¨Šã€‚åœ¨ä½¿ç”¨æˆ‘çš„å›ç­”æ™‚ï¼Œè«‹å‹™å¿…ä¿æŒæ‰¹åˆ¤æ€§æ€è€ƒï¼Œä¸¦é©—è­‰è³‡è¨Šçš„æº–ç¢ºæ€§ã€‚\n",
      "*   **æˆ‘æ²’æœ‰å€‹äººç¶“é©—:** æˆ‘æ˜¯åŸºæ–¼æ•¸æ“šè¨“ç·´çš„ï¼Œæ²’æœ‰è‡ªå·±çš„æƒ…æ„Ÿã€è§€é»æˆ–ä¿¡ä»°ã€‚\n",
      "\n",
      "**ç¸½ä¹‹ï¼Œåªè¦ä½ æå‡ºçš„è¦æ±‚åœ¨æˆ‘çš„èƒ½åŠ›ç¯„åœå…§ï¼Œæˆ‘éƒ½æœƒç›¡åŠ›å¹«åŠ©ä½ ã€‚ ä½ æƒ³è®“æˆ‘åšäº›ä»€éº¼å‘¢ï¼Ÿ**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# èŠå¤©æ¨¡å¼ç¤ºä¾‹\n",
    "model_name = \"gemma3:4b\"  # ä½¿ç”¨æ‚¨æœ‰çš„æ¨¡å‹åç¨±\n",
    "\n",
    "print(f\"\\nèˆ‡ {model_name} é€²è¡Œå°è©±...\")\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"ä½ å¥½ï¼Œä½ èƒ½å‘Šè¨´æˆ‘ä½ æ˜¯èª°å—ï¼Ÿ\"\n",
    "    }\n",
    "]\n",
    "\n",
    "try:\n",
    "    response = client.chat(\n",
    "        model=model_name,\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    assistant_message = response['message']['content']\n",
    "    print(\"\\nåŠ©ç†å›æ‡‰:\")\n",
    "    print(assistant_message)\n",
    "    \n",
    "    # å°‡åŠ©ç†å›æ‡‰æ·»åŠ åˆ°å°è©±æ­·å²\n",
    "    messages.append({\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": assistant_message\n",
    "    })\n",
    "    \n",
    "    # ç¹¼çºŒå°è©±\n",
    "    second_question = \"ä½ å¯ä»¥å¹«åŠ©æˆ‘åšä»€éº¼ï¼Ÿ\"\n",
    "    print(f\"\\nç”¨æˆ¶: {second_question}\")\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": second_question\n",
    "    })\n",
    "    \n",
    "    response = client.chat(\n",
    "        model=model_name,\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    assistant_message = response['message']['content']\n",
    "    print(\"\\nåŠ©ç†å›æ‡‰:\")\n",
    "    print(assistant_message)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"èŠå¤©æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8f85db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¦ç¾èŠå¤©æ©Ÿå™¨äººçš„å¤šè¼ªå°è©±åŠŸèƒ½\n",
    "def chat_with_model(client, model_name, initial_message=None):\n",
    "    \"\"\"\n",
    "    èˆ‡æŒ‡å®šæ¨¡å‹é€²è¡Œäº¤äº’å¼èŠå¤©\n",
    "    \n",
    "    Args:\n",
    "        client: Ollamaå®¢æˆ¶ç«¯å¯¦ä¾‹\n",
    "        model_name: è¦ä½¿ç”¨çš„æ¨¡å‹åç¨±\n",
    "        initial_message: å¯é¸çš„åˆå§‹è¨Šæ¯\n",
    "    \"\"\"\n",
    "    # åˆå§‹åŒ–å°è©±æ­·å²\n",
    "    messages = []\n",
    "    \n",
    "    # å¦‚æœæœ‰åˆå§‹è¨Šæ¯ï¼Œæ·»åŠ åˆ°å°è©±æ­·å²\n",
    "    if initial_message:\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": initial_message\n",
    "        })\n",
    "        \n",
    "        try:\n",
    "            response = client.chat(model=model_name, messages=messages)\n",
    "            assistant_message = response['message']['content']\n",
    "            print(\"\\nåŠ©ç†å›æ‡‰:\")\n",
    "            print(assistant_message)\n",
    "            \n",
    "            # å°‡åŠ©ç†å›æ‡‰æ·»åŠ åˆ°å°è©±æ­·å²\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": assistant_message\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"èŠå¤©æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
    "            return\n",
    "    \n",
    "    print(f\"\\né–‹å§‹èˆ‡ {model_name} çš„å°è©±ã€‚è¼¸å…¥ 'exit' æˆ– 'quit' çµæŸå°è©±ã€‚\")\n",
    "    \n",
    "    # é–‹å§‹å°è©±å¾ªç’°\n",
    "    while True:\n",
    "        # ç²å–ç”¨æˆ¶è¼¸å…¥\n",
    "        user_input = input(\"\\nä½ : \")\n",
    "        \n",
    "        # æª¢æŸ¥æ˜¯å¦é€€å‡º\n",
    "        if user_input.lower() in ['exit', 'quit']:\n",
    "            print(\"å°è©±çµæŸ\")\n",
    "            break\n",
    "        \n",
    "        # æ·»åŠ ç”¨æˆ¶è¨Šæ¯åˆ°å°è©±æ­·å²\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_input\n",
    "        })\n",
    "        \n",
    "        try:\n",
    "            # ç²å–æ¨¡å‹å›æ‡‰\n",
    "            print(\"æ¨¡å‹æ€è€ƒä¸­...\", end=\"\\r\")\n",
    "            response = client.chat(model=model_name, messages=messages)\n",
    "            assistant_message = response['message']['content']\n",
    "            \n",
    "            # æ¸…é™¤æ€è€ƒä¸­çš„æç¤º\n",
    "            print(\" \" * 20, end=\"\\r\")\n",
    "            \n",
    "            # é¡¯ç¤ºåŠ©ç†å›æ‡‰\n",
    "            print(\"\\nåŠ©ç†: \")\n",
    "            print(assistant_message)\n",
    "            \n",
    "            # å°‡åŠ©ç†å›æ‡‰æ·»åŠ åˆ°å°è©±æ­·å²\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": assistant_message\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"èŠå¤©æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
    "            break\n",
    "    \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a60fb5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab327e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
