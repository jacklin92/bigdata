{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "471af8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在檢查 Ollama 服務器連接 (http://163.18.22.32:11435)...\n",
      "連接成功！可用模型: gemma3:4b\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import sys\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# 設置 Ollama 服務器地址\n",
    "OLLAMA_HOST = \"http://163.18.22.32:11435\"\n",
    "ollama.host = OLLAMA_HOST\n",
    "\n",
    "# 在程式開始時檢查連接\n",
    "print(f\"正在檢查 Ollama 服務器連接 ({OLLAMA_HOST})...\")\n",
    "try:\n",
    "    # 嘗試獲取可用模型列表以測試連接\n",
    "    response = requests.get(f\"{OLLAMA_HOST}/api/tags\")\n",
    "    if response.status_code == 200:\n",
    "        models = response.json()\n",
    "        available_models = [model['name'] for model in models['models']]\n",
    "        print(f\"連接成功！可用模型: {', '.join(available_models)}\")\n",
    "    else:\n",
    "        print(f\"連接失敗，服務器返回狀態碼: {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"無法連接到 Ollama 服務器: {e}\")\n",
    "    print(\"請檢查:\")\n",
    "    print(\"1. Ollama 服務器是否正在運行\")\n",
    "    print(\"2. 網絡連接是否正常\")\n",
    "    print(\"3. 防火牆設置是否允許連接\")\n",
    "    print(\"4. IP 地址和端口是否正確\")\n",
    "    sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce6946ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "使用 gemma3:4b 生成內容...\n",
      "\n",
      "回應:\n",
      "好的，我來用簡單的語言解釋什麼是「大數據分析」：\n",
      "\n",
      "**想像一下，你擁有一堆東西，數量非常非常多，而且你還想從這些東西中找到一些有用的資訊。**\n",
      "\n",
      "**大數據分析就是利用專門的技術和方法，去處理、分析這些超級龐大的數據，並從中發現有價值的資訊。**\n",
      "\n",
      "更詳細的解釋：\n",
      "\n",
      "* **什麼是「大數據」？**  \n",
      "    * 指的是比傳統的數據（例如：一個表格裡的一筆記錄）龐大得多的數據集合。 \n",
      "    * 通常指資料量很大（TB、PB甚至更大），而且可能同時具有**多樣性**（例如：文字、圖片、影片、聲音、位置資訊等等）和**高速**（持續不斷地產生）。 \n",
      "* **大數據分析的步驟：**\n",
      "    1. **收集數據：** 從各種來源收集數據，例如網站、社交媒體、感測器、銷售記錄等等。\n",
      "    2. **清洗數據：** 數據通常會有很多錯誤、重複或缺失的部分，需要進行清理和整理。\n",
      "    3. **分析數據：** 利用各種技術（例如：統計分析、機器學習）從數據中找出模式、趨勢、關係等。\n",
      "    4. **呈現結果：** 將分析結果以圖表、報告或其他形式呈現出來，方便人們理解和使用。\n",
      "\n",
      "**大數據分析的應用：**\n",
      "\n",
      "* **商業：** 了解顧客喜好，優化產品和服務，提高銷售額。\n",
      "* **醫療：** 預測疾病風險，改善治療效果。\n",
      "* **金融：** 預防詐欺，評估風險。\n",
      "* **交通：** 改善交通流量，預測交通擁堵。\n",
      "* **政府：** 提高公共服務效率，改善社會治理。\n",
      "\n",
      "**簡單來說，大數據分析就像一個超級偵探，它能從海量數據中挖掘出隱藏的智慧！**\n",
      "\n",
      "希望這個解釋對您有幫助！  如果您還有其他問題，歡迎隨時提出。\n"
     ]
    }
   ],
   "source": [
    "# 使用 requests 直接調用 Ollama API 生成文本\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# 設置 Ollama 服務器地址\n",
    "OLLAMA_HOST = \"http://163.18.22.32:11435\"\n",
    "\n",
    "# 簡單的文本生成示例\n",
    "model_name = \"gemma3:4b\"  # 使用您有的模型名稱\n",
    "prompt = \"解釋什麼是大數據分析？請用簡單的語言說明。\"\n",
    "\n",
    "print(f\"\\n使用 {model_name} 生成內容...\")\n",
    "try:\n",
    "    # 構建 API 請求\n",
    "    url = f\"{OLLAMA_HOST}/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    # 發送請求\n",
    "    response = requests.post(url, json=payload)\n",
    "    \n",
    "    # 檢查響應\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        print(\"\\n回應:\")\n",
    "        print(result['response'])\n",
    "    else:\n",
    "        print(f\"API 返回錯誤: {response.status_code}\")\n",
    "        print(response.text)\n",
    "except Exception as e:\n",
    "    print(f\"生成時發生錯誤: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9316914a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "與 gemma3:4b 進行對話...\n",
      "\n",
      "助理回應:\n",
      "我是 Gemma，一個由 Google DeepMind 訓練的大型語言模型。我是一個開放權重的 AI 助理。\n",
      "\n",
      "我能夠接收文字和圖像作為輸入，並產生文字作為輸出。 \n",
      "\n",
      "你可以把我當作一個可以和你聊天、回答問題、以及協助你完成各種文字任務的工具。\n"
     ]
    }
   ],
   "source": [
    "# 使用 requests 直接調用 Ollama API 進行聊天\n",
    "import requests\n",
    "\n",
    "# 設置 Ollama 服務器地址\n",
    "OLLAMA_HOST = \"http://163.18.22.32:11435\"\n",
    "\n",
    "# 聊天示例\n",
    "model_name = \"gemma3:4b\"  # 使用您有的模型名稱\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"你好，你能告訴我你是誰嗎？\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"\\n與 {model_name} 進行對話...\")\n",
    "try:\n",
    "    # 構建 API 請求\n",
    "    url = f\"{OLLAMA_HOST}/api/chat\"\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    # 發送請求\n",
    "    response = requests.post(url, json=payload)\n",
    "    \n",
    "    # 檢查響應\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        assistant_message = result['message']['content']\n",
    "        print(\"\\n助理回應:\")\n",
    "        print(assistant_message)\n",
    "    else:\n",
    "        print(f\"API 返回錯誤: {response.status_code}\")\n",
    "        print(response.text)\n",
    "except Exception as e:\n",
    "    print(f\"聊天時發生錯誤: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69c01caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "使用 gemma3:4b 串流生成內容...\n",
      "\n",
      "回應: 好的，以下是一個關於資料科學重要性的短文：\n",
      "\n",
      "**資料科學：驅動決策的關鍵力量**\n",
      "\n",
      "在當今這個資訊爆炸的時代，大量數據每天都在產生。然而，這些數據本身並不能帶來任何價值。只有透過**資料科學**，我們才能將這些數字轉化為有意義的洞見，從而做出更明智的決策。\n",
      "\n",
      "資料科學是一個跨領域的學科，結合了統計學、機器學習、數據庫管理、商業智慧等技術。它的核心價值在於：\n",
      "\n",
      "*   **發現模式與趨勢：** 資料科學家利用複雜的算法和統計方法，從海量數據中提取有價值的模式和趨勢，揭示潛在的機會或風險。\n",
      "*   **優化決策：** 這些洞見可以應用於各種領域，例如市場營銷、產品開發、醫療保健、金融服務等，幫助企業和組織做出更有效的決策。\n",
      "*   **提升效率與自動化：** 機器學習和人工智能技術，是資料科學的重要組成部分，可以自動化重複性任務，提高工作效率。\n",
      "*   **個性化體驗：** 資料科學可以分析用戶行為，為他們提供更具個人化的產品、服務和內容。\n",
      "\n",
      "從商業到科學，從政府到非營利組織，資料科學正日益成為各行各業不可或缺的關鍵力量。隨著數據量的持續增長，資料科學的重要性將更加凸顯，它將繼續塑造我們的世界，並為我們帶來更美好的未來。\n",
      "\n",
      "---\n",
      "\n",
      "希望這篇文章符合您的要求！您還可以告訴我，您希望短文的重點是什麼，我可以根據您的需求進行調整。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用 requests 直接調用 Ollama API 進行串流生成\n",
    "import requests\n",
    "\n",
    "# 設置 Ollama 服務器地址\n",
    "OLLAMA_HOST = \"http://163.18.22.32:11435\"\n",
    "\n",
    "# 串流生成示例\n",
    "model_name = \"gemma3:4b\"  # 使用您有的模型名稱\n",
    "prompt = \"撰寫一個關於資料科學重要性的短文。\"\n",
    "\n",
    "print(f\"\\n使用 {model_name} 串流生成內容...\")\n",
    "print(\"\\n回應: \", end=\"\", flush=True)\n",
    "try:\n",
    "    # 構建 API 請求\n",
    "    url = f\"{OLLAMA_HOST}/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": True\n",
    "    }\n",
    "    \n",
    "    # 發送串流請求\n",
    "    with requests.post(url, json=payload, stream=True) as response:\n",
    "        if response.status_code == 200:\n",
    "            for line in response.iter_lines():\n",
    "                if line:\n",
    "                    # 解析 JSON 數據\n",
    "                    data = json.loads(line.decode('utf-8'))\n",
    "                    if 'response' in data:\n",
    "                        print(data['response'], end=\"\", flush=True)\n",
    "            print(\"\\n\")\n",
    "        else:\n",
    "            print(f\"\\nAPI 返回錯誤: {response.status_code}\")\n",
    "            print(response.text)\n",
    "except Exception as e:\n",
    "    print(f\"\\n生成時發生錯誤: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625cac2d",
   "metadata": {},
   "source": [
    "# 另一方式使用chat() generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd9d3279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "# 設置遠程 Ollama 模型的基礎 URL\n",
    "REMOTE_OLLAMA_URL = \"http://163.18.22.32:11435\"\n",
    "# 創建客戶端實例\n",
    "client = ollama.Client(host=REMOTE_OLLAMA_URL)\n",
    "\n",
    "# 設置要使用的模型名稱\n",
    "model_name = \"gemma3:4b\" # 默認模型名稱\n",
    "#model_name = \"llama3:latest\"\n",
    "#model_name = \"deepseek-r1:7b\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f7cb15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# This is a markdown heading\n",
       "\n",
       "- This is a bullet point\n",
       "- Another bullet point\n",
       "\n",
       "**Bold text** and *italic text*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def display_markdown(text):\n",
    "    \"\"\"\n",
    "    Display text as rendered markdown in the notebook\n",
    "    \n",
    "    Args:\n",
    "        text (str): The markdown text to render\n",
    "    \"\"\"\n",
    "    display(Markdown(text))\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Example usage\n",
    "example_text = \"\"\"\n",
    "# This is a markdown heading\n",
    "\n",
    "- This is a bullet point\n",
    "- Another bullet point\n",
    "\n",
    "**Bold text** and *italic text*\n",
    "\"\"\"\n",
    "display_markdown(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89c9e996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# This is a markdown heading\n",
       "\n",
       "- This is a bullet point\n",
       "- Another bullet point\n",
       "\n",
       "**Bold text** and *italic text*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(example_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "650a2be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# This is a markdown heading\n",
       "\n",
       "- This is a bullet point\n",
       "- Another bullet point\n",
       "\n",
       "**Bold text** and *italic text*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e6c14d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "使用 gemma3:4b 生成內容...\n",
      "\n",
      "回應:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "大數據分析，簡單來說就是：**從海量數據中找到有用的資訊和趨勢，幫助我們做出更好的決策。**\n",
       "\n",
       "想像一下，你收集了所有顧客的購物紀錄、社群媒體上的評論、網站瀏覽記錄等等，這些資料量非常非常大，如果沒辦法處理，就變成一堆亂七八糟的數字和文字。\n",
       "\n",
       "大數據分析就是幫你：\n",
       "\n",
       "1. **收集和整理數據：** 就像收集所有這些信息。\n",
       "2. **篩選和清理數據：** 像把垃圾丟掉，只留下有用的信息。\n",
       "3. **分析數據：** 運用各種方法（像是統計學、機器學習等）去挖掘數據裡面的模式、趨勢和關係。\n",
       "4. **呈現結果：** 將分析結果以圖表、報告等形式呈現出來，讓大家能清楚地了解情況。\n",
       "\n",
       "**舉個例子：**\n",
       "\n",
       "* **零售業：** 分析顧客的購物記錄，可以知道哪些商品常常一起買，哪些顧客傾向於購買特定品牌，從而制定更有效的促銷活動和商品組合。\n",
       "* **醫療保健：** 分析病人的病歷、基因數據等，可以幫助醫生更準確地診斷疾病，並找到更有效的治療方法。\n",
       "* **交通運輸：** 分析交通流量數據，可以優化交通路線，減少交通擁堵。\n",
       "\n",
       "**總之，大數據分析不只是看數據，更重要的是利用數據來解決問題、做出更好的決策。**\n",
       "\n",
       "希望這個解釋對你有幫助！\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 簡單的文本生成示例\n",
    "model_name = \"gemma3:4b\"  # 使用您有的模型名稱\n",
    "prompt = \"解釋什麼是大數據分析？請用簡單的語言說明。\"\n",
    "\n",
    "print(f\"\\n使用 {model_name} 生成內容...\")\n",
    "try:\n",
    "    response = client.generate(\n",
    "        model=model_name,\n",
    "        prompt=prompt\n",
    "    )\n",
    "    print(\"\\n回應:\")\n",
    "    display(Markdown(response['response']))\n",
    "except Exception as e:\n",
    "    print(f\"生成時發生錯誤: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f934c87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "使用 gemma3:4b 串流生成內容...\n",
      "\n",
      "回應: 以下是一篇關於資料科學重要性的短文：\n",
      "\n",
      "**資料科學：驅動現代決策的引擎**\n",
      "\n",
      "在當今數據爆炸的時代，資料科學已不再僅僅是數據科學家的專屬領域，而是成為各行各業取得成功的關鍵驅動力。資料科學是一門跨領域的學科，它結合了統計學、機器學習、數據分析和商業智慧，利用複雜的算法和工具，從大量數據中提取有價值的信息和洞見。\n",
      "\n",
      "**資料科學的重要性體現在以下幾個方面：**\n",
      "\n",
      "* **提高決策效率：** 透過深入分析數據，資料科學能夠幫助企業和組織更好地理解市場趨勢、客戶行為和運營效率，從而做出更明智的商業決策，例如產品開發、市場行銷和投資策略。\n",
      "* **個性化體驗：** 透過分析客戶數據，企業可以為客戶提供個性化的產品推薦、定制化服務和針對性的行銷活動，從而提升客戶滿意度和忠誠度。\n",
      "* **優化運營效率：** 資料科學可以應用於各種運營領域，例如供應鏈管理、生產流程優化和資源分配，從而降低成本、提高效率並減少浪費。\n",
      "* **風險預測與管理：** 透過分析歷史數據和趨勢，資料科學可以幫助預測潛在的風險，例如金融風險、信用風險和安全風險，從而及時採取預防措施。\n",
      "* **創新發展：** 資料科學正在推動各個領域的創新發展，例如醫療健康、交通運輸和能源等，為解決複雜的問題和創造新的機會提供了可能性。\n",
      "\n",
      "總之，資料科學不僅僅是處理數據的技術，更是一種思考方式和解決問題的方法。 隨著數據量的持續增長，資料科學的重要性將不斷加強，並在塑造未來世界方面發揮著越來越重要的作用。\n",
      "\n",
      "---\n",
      "\n",
      "希望這篇短文對您有所幫助!  如果您有任何其他要求，請隨時提出。\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用流式輸出生成文本\n",
    "model_name = \"gemma3:4b\"  # 使用您有的模型名稱\n",
    "prompt = \"撰寫一個關於資料科學重要性的短文。\"\n",
    "\n",
    "print(f\"\\n使用 {model_name} 串流生成內容...\")\n",
    "print(\"\\n回應: \", end=\"\", flush=True)\n",
    "try:\n",
    "    for chunk in client.generate(\n",
    "        model=model_name,\n",
    "        prompt=prompt,\n",
    "        stream=True\n",
    "    ):\n",
    "        content = chunk['response']\n",
    "        print(content, end=\"\", flush=True)\n",
    "        time.sleep(0.01)  # 小延遲以更好地模擬生成\n",
    "    print(\"\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n生成時發生錯誤: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f3dc7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "與 gemma3:4b 進行對話...\n",
      "\n",
      "助理回應:\n",
      "我是 Google 訓練的大型語言模型。\n",
      "\n",
      "簡單來說，我是一個大型的 AI 模型，可以理解和生成人類語言。 我可以：\n",
      "\n",
      "*   回答你的問題，盡力提供準確和全面的答案。\n",
      "*   根據你的指示生成不同的文本格式，例如詩歌、程式碼、劇本、音樂作品、電子郵件、信件等。\n",
      "*   翻譯語言。\n",
      "*   總結文本。\n",
      "*   提供資訊。\n",
      "\n",
      "我仍在不斷學習和改進中，我的知識截至到 2023 年 4 月。\n",
      "\n",
      "希望這個回答對你有幫助！ 如果你還有其他問題，隨時可以問我。\n",
      "\n",
      "\n",
      "用戶: 你可以幫助我做什麼？\n",
      "\n",
      "助理回應:\n",
      "我可以幫助你做很多事情！ 以下是一些我可以做的事情的分類，希望能給你一個更清晰的了解：\n",
      "\n",
      "**1. 信息與知識:**\n",
      "\n",
      "*   **回答問題:** 任何你想要了解的事情，我可以試著回答，從歷史事件到科學概念，再到生活瑣事。\n",
      "*   **提供信息:** 比如告訴你某個城市的天氣，某個歷史人物的生平，或者某個產品的規格。\n",
      "*   **總結文本:** 如果你給我一篇長篇文章或報告，我可以幫你概括重點。\n",
      "*   **翻譯:** 我可以將文本從一種語言翻譯成另一種語言。\n",
      "*   **搜索信息:** 雖然我不能像搜索引擎一樣直接瀏覽網際網路，但我可以根據你的指示，用我所掌握的知識來提取信息，然後整理成更易懂的形式。\n",
      "\n",
      "**2. 創作與生成:**\n",
      "\n",
      "*   **寫作:**\n",
      "    *   **文章:**  我可以幫你寫文章、故事、詩歌、劇本等等。\n",
      "    *   **郵件/信件:**  我可以幫你撰寫各種風格的郵件或信件。\n",
      "    *   **標題/描述:** 我可以為你的產品、網站或文章生成標題或描述。\n",
      "*   **創意生成:**  我可以根據你的提示生成各種創意內容，比如故事想法、角色設定、音樂旋律等等。\n",
      "*   **程式碼生成:**  我可以生成一些簡單的程式碼，例如 Python、JavaScript 等。 (但要注意，我生成的程式碼可能需要你進行修改和測試)\n",
      "\n",
      "**3. 輔助學習:**\n",
      "\n",
      "*   **解釋概念:** 只要你提出一個你不理解的概念，我會盡力用簡單的方式解釋給你聽。\n",
      "*   **練習:**  我們可以一起練習語言、數學、邏輯等等。\n",
      "*   **提供建議:**  在某些情況下，我可以提供一些建議 (但請記住，我不是專業人士，我的建議僅供參考)。\n",
      "\n",
      "**4.  娛樂:**\n",
      "\n",
      "*   **講故事:**  我可以講故事給你聽。\n",
      "*   **玩文字遊戲:** 我們可以一起玩一些文字遊戲，比如猜謎語、成語接龍等等。\n",
      "\n",
      "\n",
      "**重要提示:**\n",
      "\n",
      "*   **我的知識有限:** 我的知識截止到 2023 年 4 月。\n",
      "*   **我不是完美的:** 我可能會犯錯，請仔細檢查我提供的信息。\n",
      "*   **我是一個工具:**  請善用我，但也要保持批判性思考。\n",
      "\n",
      "**為了更好地幫助你，請告訴我：**\n",
      "\n",
      "*   你現在想讓我做什麼？\n",
      "*   你有什麼具體需求？\n",
      "\n",
      "有了更清晰的指示，我才能更好地為你服務! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 聊天模式示例\n",
    "model_name = \"gemma3:4b\"  # 使用您有的模型名稱\n",
    "\n",
    "print(f\"\\n與 {model_name} 進行對話...\")\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"你好，你能告訴我你是誰嗎？\"\n",
    "    }\n",
    "]\n",
    "\n",
    "try:\n",
    "    response = client.chat(\n",
    "        model=model_name,\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    assistant_message = response['message']['content']\n",
    "    print(\"\\n助理回應:\")\n",
    "    print(assistant_message)\n",
    "    \n",
    "    # 將助理回應添加到對話歷史\n",
    "    messages.append({\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": assistant_message\n",
    "    })\n",
    "    \n",
    "    # 繼續對話\n",
    "    second_question = \"你可以幫助我做什麼？\"\n",
    "    print(f\"\\n用戶: {second_question}\")\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": second_question\n",
    "    })\n",
    "    \n",
    "    response = client.chat(\n",
    "        model=model_name,\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    assistant_message = response['message']['content']\n",
    "    print(\"\\n助理回應:\")\n",
    "    print(assistant_message)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"聊天時發生錯誤: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8f85db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 實現聊天機器人的多輪對話功能\n",
    "def chat_with_model(client, model_name, initial_message=None):\n",
    "    \"\"\"\n",
    "    與指定模型進行交互式聊天\n",
    "    \n",
    "    Args:\n",
    "        client: Ollama客戶端實例\n",
    "        model_name: 要使用的模型名稱\n",
    "        initial_message: 可選的初始訊息\n",
    "    \"\"\"\n",
    "    # 初始化對話歷史\n",
    "    messages = []\n",
    "    \n",
    "    # 如果有初始訊息，添加到對話歷史\n",
    "    if initial_message:\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": initial_message\n",
    "        })\n",
    "        \n",
    "        try:\n",
    "            response = client.chat(model=model_name, messages=messages)\n",
    "            assistant_message = response['message']['content']\n",
    "            print(\"\\n助理回應:\")\n",
    "            print(assistant_message)\n",
    "            \n",
    "            # 將助理回應添加到對話歷史\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": assistant_message\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"聊天時發生錯誤: {e}\")\n",
    "            return\n",
    "    \n",
    "    print(f\"\\n開始與 {model_name} 的對話。輸入 'exit' 或 'quit' 結束對話。\")\n",
    "    \n",
    "    # 開始對話循環\n",
    "    while True:\n",
    "        # 獲取用戶輸入\n",
    "        user_input = input(\"\\n你: \")\n",
    "        \n",
    "        # 檢查是否退出\n",
    "        if user_input.lower() in ['exit', 'quit']:\n",
    "            print(\"對話結束\")\n",
    "            break\n",
    "        \n",
    "        # 添加用戶訊息到對話歷史\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_input\n",
    "        })\n",
    "        \n",
    "        try:\n",
    "            # 獲取模型回應\n",
    "            print(\"模型思考中...\", end=\"\\r\")\n",
    "            response = client.chat(model=model_name, messages=messages)\n",
    "            assistant_message = response['message']['content']\n",
    "            \n",
    "            # 清除思考中的提示\n",
    "            print(\" \" * 20, end=\"\\r\")\n",
    "            \n",
    "            # 顯示助理回應\n",
    "            print(\"\\n助理: \")\n",
    "            print(assistant_message)\n",
    "            \n",
    "            # 將助理回應添加到對話歷史\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": assistant_message\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"聊天時發生錯誤: {e}\")\n",
    "            break\n",
    "    \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a60fb5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab327e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
